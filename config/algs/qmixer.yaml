
fc_hidden_dim:  64

egreedy_exploration: 1
min_exploration: 0.05
target_update_tau: 0.05
target_update_interval:  200
lr: 0.0005
critic_lr: 0.0005
td_lambda: 1.0
learning_rate: 0.1
min_learning_rate: 0.00001
clip_grad_norm:  10
hypernet_layers: 1
hypernet_embed_dim:  32
mixing_embed_dim:  32
learner_update_freq:  5
hyper_initialization_nonzeros: 0
double_q:  False
replay_buffer_size:  1000
batch_size_run: 1 # Off policy uses experience replay
optimizer_type: 'rmsprop'
memory_warmup_size: 32
nonlinear_key: False
qtran_arch: "qtran_paper"
opt_loss: 1
nopt_min_loss: 0.1
buffer_size: 1000
rnn_hidden_dim: 128
eps_limit: 1
policy_ent_coeff: 0.03
ten: True

mixer: ""
mixer_hidden_dim: 32
hypernet_hidden_dim: 64

unit_dim: 1
n_heads: 2
state_bias: True
weighted_head: True
mask_dead: False
attend_reg_coef: 1


network_size: small


learner: "qmixer_learner"
name: "qmixer"

