# --- COMA specific parameters ---

action_selector: "multinomial"
epsilon_start: .8
epsilon_finish: .01
epsilon_anneal_time: 2000000
mask_before_softmax: False
use_centralized_V: True

runner: "elign_runner"  # parallele or episode


buffer_size: 2000000
batch_size_run: 32 # number of env to run in parralelel
batch_size: 32 # Number of episodes to train on

# update the target network every {} training steps
target_update_interval: 200

actor_lr: 0.0005
critic_lr: 0.001
td_lambda: 1.0

# use MAPPO
agent_output_type: "pi_logits"
learner: "elign_learner"
critic_q_fn: "ppo"
critic_train_mode: "seq"
critic_train_reps: 1
q_nstep: 0  # 0 corresponds to default Q, 1 is r + gamma*Q, etc
name: "elign"


task: "simple_spread_in"
save_video: False
save_models: False
benchmark: False
video_file: "videos/simple.mp4"
seed: 0
logdir: "log"
checkpoint: None
render: 0
epoch: 1
step_per_epoch: 5
collect_per_step: 100
training_num: 100
test_num: 25
layer_num: 2
tau: 0.01
gamma: 0.95
alpha: 0.1
rew_norm: 1
ignore_done: 0
n_step: 1

num_good_agents: 0
num_adversaries: 0
obs_radius: 3
amb_init: 0
rew_shape: False
grads_logging: False
intr_rew: "elign_team" # options include ['no', 'elign_self', 'elign_team', 'elign_adv', 'elign_both', 'curio_self', 'curio_team']
wm_noise_level: 0.0 # add noise to world model or not
share_buffer: True
landmarks: [0]



